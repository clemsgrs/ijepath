# Run template (copy/edit for a concrete training run).
# This file is merged on top of:
# - configs/defaults.yaml
# - a chosen profile config

data:
  # Batch/memory/runtime (defaults from defaults.yaml).
  batch_size_per_gpu: 32  # Per-GPU microbatch. Global batch = batch_size_per_gpu * world_size.
  pin_mem: true
  num_workers: 16
  samples_per_epoch: 200000  # Set null for strict one-pass-per-epoch semantics.
  seed: 0
  wsi_backend: openslide

  # Required run-specific paths.
  # Defaults in defaults.yaml are null and must be set for a real run.
  slide_manifest_csv: null
  slide_metadata_index_jsonl: null
  anchor_catalog_csv: null

  # Geometry and spacing are usually provided by the profile config.
  # Keep these unset here unless you intentionally override profile values.
  # Final model tensor sizes are derived as nearest multiples of meta.patch_size:
  # context_px = snap(round(context_fov_um / context_mpp), patch_size)
  # target_px = snap(round(target_fov_um / target_mpp), patch_size)
  context_mpp: null
  target_mpp: null
  context_fov_um: null
  target_fov_um: null
  targets_per_context: null

  # Tissue-aware target sampling (defaults from defaults.yaml).
  min_target_tissue_fraction: 0.25
  insufficient_target_policy: skip_anchor  # skip_anchor | skip_slide | lower_threshold
  min_target_tissue_fraction_floor: 0.10
  min_target_tissue_fraction_step: 0.05

  # Requested-vs-source spacing matching tolerance.
  spacing_tolerance: 0.05

meta:
  copy_data: false
  load_checkpoint: false
  architecture: vit_small
  patch_size: 16
  pred_depth: 3
  pred_emb_dim: 192
  read_checkpoint: null
  use_bfloat16: true

mask:
  num_enc_masks: 1
  num_pred_masks: null  # Null => auto-set to data.targets_per_context at config load time.
  min_keep: 16

optimization:
  ema: [0.996, 1.0]
  epochs: 100
  final_lr: 1.0e-06
  final_weight_decay: 0.1
  ipe_scale: 1.0
  lr: 0.0002
  start_lr: 0.00002
  warmup: 0.1
  weight_decay: 0.04

logging:
  folder: outputs/run
  write_tag: jepa-run
  step_log_every_iters: 0  # 0 => disable per-step terminal logs and rely on epoch summaries.
  checkpoint_every_epochs: 50  # Save numbered checkpoint every N epochs, plus always keep latest.

wandb:
  enable: false
  project: ijepath
  username: null
  exp_name: null
  tags: []
  dir: null
  group: null
  resume_id: null
